# python笔记 基于线程的socket通信,守护线程,互斥锁,递归锁,死锁,信号量,事件,条件,定时器,线程队列,concurrent.feature模块,进程池与线程池

## 基于线程的socket通信

- 服务端

  ```python
  import socket
  from threading import Thread
  from config import common
  
  
  def handle_conn(conn, addr):
      print(f'客户端地址 {addr}')
      while 1:
          data_recv = conn.recv(common.BUF)
          print(f'接收数据 {data_recv}')
          conn.send(data_recv.upper())
  
  
  if __name__ == '__main__':
      sk = socket.socket()
      sk.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
      sk.bind(common.IP_PORT)
      sk.listen()
  
      print(f'服务端开启')
  
      try:
          while 1:
              conn, addr = sk.accept()
              th = Thread(target=handle_conn, args=(conn, addr))
              th.start()
      finally:
          sk.close()
  ```

- 客户端

  ```python
  import socket
  from config import common
  
  sk = socket.socket()
  sk.connect(common.IP_PORT)
  
  while 1:
      data = input(">>> ").strip()
  
      if not data or data == 'q':
          break
  
      sk.send(bytes(data, common.ENCODING))
      data_recv = sk.recv(common.BUF).decode(common.ENCODING)
      print(data_recv)
  
  sk.close()
  ```

## Thread类的其他方法

- Thread实例对象的方法
  - isAlive(): 返回线程是否活动的
  - getName(): 返回线程名
  - setName(): 设置线程名
- threading模块提供的一些方法
  - threading.currentThread(): 返回当前的线程变量
  - threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程
  - threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果

```python
from threading import Thread
import threading


def func():
    th = threading.currentThread()
    # 获取线程名称
    print(th.name)

    # 获取线程的标识符
    # 线程标识符是一个非零整数
    print(th.ident)

    # 是否处于活动中
    print(th.isAlive())

    # 是否为守护线程
    print(th.isDaemon())


if __name__ == '__main__':
    th = Thread(target=func, name=f'子线程1')
    th.start()
```

## 守护线程

- **无论是进程还是线程，都遵循：守护xx会等待主xx运行完毕后被销毁。需要强调的是：运行完毕并非终止运行**
  1. 对主进程来说，运行完毕指的是主进程代码运行完毕
  2. 对主线程来说，运行完毕指的是主线程所在的进程内所有非守护线程统统运行完毕，主线程才算运行完毕

```python
from threading import Thread
import time


def func():
    time.sleep(2)
    print('子线程执行代码')


if __name__ == '__main__':
    th = Thread(target=func, name=f'子线程1')
    th.start()
    print('主线程执行代码')


# 未设置守护线程的情况:
# 主线程执行代码
# 子线程执行代码
```

```python
from threading import Thread
import time


def func():
    time.sleep(2)
    print('子线程执行代码')


if __name__ == '__main__':
    th = Thread(target=func, name=f'子线程1')
    # 设置为守护线程
    th.setDaemon(True)
    th.start()
    print('主线程执行代码')

# 守护线程的情况:
# 主线程执行代码
```

```python
from threading import Thread
import time


def func():
    time.sleep(2)
    print('子线程执行代码')


if __name__ == '__main__':
    th = Thread(target=func, name=f'子线程1')
    # 设置为守护线程
    th.setDaemon(True)
    th.start()

    # 等待子线程执行完毕
    th.join()

    print('主线程执行代码')

# 子线程执行代码
# 主线程执行代码
```

## 锁

- 对于线程来说, 虽然 Python 提供了全局解释器锁 GIL , 但是实际上在多线程操作相同的数据时, 仍需要进行加载处理

### 多线程抢占资源

- 不使用锁的情况, 多线程操作数据有可能出现数据的不安全问题

  ```python
  from threading import Thread
  import time
  import random
  
  
  def func():
      global data
      temp = data
      # 模拟延时
      time.sleep(random.random())
      temp = temp - 1
      data = temp
  
  
  if __name__ == '__main__':
      thread_num = 5
  
      data = thread_num
  
      thread_list = []
      for item in range(thread_num):
          th = Thread(target=func)
          thread_list.append(th)
  
      [item.start() for item in thread_list]
      [item.join() for item in thread_list]
  
      print(data)
  
  # 4
  ```

### 互斥锁

```python
from threading import Thread
import time
import random
from threading import Lock


def func():
    global data
    # 申请锁
    lock.acquire()

    temp = data
    # 模拟延时
    time.sleep(random.random())
    temp = temp - 1
    data = temp

    # 释放锁
    lock.release()


if __name__ == '__main__':
    thread_num = 5

    # 多线程同时操作 data 数据
    data = thread_num

    # 创建互斥锁
    lock = Lock()

    thread_list = []
    for item in range(thread_num):
        th = Thread(target=func)
        thread_list.append(th)

    [item.start() for item in thread_list]
    [item.join() for item in thread_list]

    print(data)
    
# 0    
```

### 死锁

- 是指两个或两个以上的进程或线程在执行过程中, 因争夺资源而造成的一种互相等待的现象, 若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程

- 线程中的死锁

  ```python
  from threading import Thread
  import threading
  import time
  import random
  from threading import Lock
  
  
  def func1():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
  
  def func2():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      lock_a = Lock()
      lock_b = Lock()
  
      th1 = Thread(target=func1, name=f'线程1')
      th2 = Thread(target=func2, name=f'线程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'子线程执行完毕')
  
  # 线程1 获取到 A 锁
  # 线程2 获取到 B 锁
  
  
  # 问题现象:
  # 线程1需要抢占 B 锁, 但是被线程2抢占了
  # 线程2需要抢占 A 锁, 但是被线程1抢占了
  # 程序卡住
  ```

- 进程中的死锁

  ```python
  from multiprocessing import Process
  from multiprocessing import Lock
  import multiprocessing
  import time
  import random
  
  
  def func1():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
  
  def func2():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      lock_a = Lock()
      lock_b = Lock()
  
      th1 = Process(target=func1, name=f'进程1')
      th2 = Process(target=func2, name=f'进程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'进程执行完毕')
  
  # 进程1 获取到 A 锁
  # 进程2 获取到 B 锁
  ```

### 递归锁

- Python中为了支持在同一线程中多次请求同一资源，python提供了可重入锁RLock

- 处理线程的死锁问题

  ```python
  from threading import Thread
  import threading
  import time
  import random
  from threading import Lock
  from threading import RLock
  
  
  def func1():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
  
  def func2():
      th = threading.current_thread()
      thread_name = th.name
  
      lock_b.acquire()
      print(f'{thread_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{thread_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{thread_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{thread_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      # 将互斥锁 Lock 替换为 递归锁 RLock
      lock_a = lock_b = RLock()
  
      th1 = Thread(target=func1, name=f'线程1')
      th2 = Thread(target=func2, name=f'线程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'子线程执行完毕')
  
  # 线程1 获取到 A 锁
  # 线程1 获取到 B 锁
  # 线程1 释放 B 锁
  # 线程1 释放 A 锁
  # 线程2 获取到 B 锁
  # 线程2 获取到 A 锁
  # 线程2 释放 A 锁
  # 线程2 释放 B 锁
  # 子线程执行完毕
  ```

- 处理进程的死锁问题

  ```python
  from multiprocessing import Process
  from multiprocessing import RLock
  import multiprocessing
  import time
  import random
  
  
  def func1():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      time.sleep(random.random())
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
  
  def func2():
      pro = multiprocessing.current_process()
      progress_name = pro.name
  
      lock_b.acquire()
      print(f'{progress_name} 获取到 B 锁')
  
      time.sleep(random.random())
  
      lock_a.acquire()
      print(f'{progress_name} 获取到 A 锁')
  
      lock_a.release()
      print(f'{progress_name} 释放 A 锁')
  
      lock_b.release()
      print(f'{progress_name} 释放 B 锁')
  
  
  if __name__ == '__main__':
      # 同样替换为递归锁 RLock
      lock_a = lock_b = RLock()
  
      th1 = Process(target=func1, name=f'进程1')
      th2 = Process(target=func2, name=f'进程2')
  
      th1.start()
      th2.start()
  
      th1.join()
      th2.join()
      print(f'进程执行完毕')
  
  # 进程1 获取到 A 锁
  # 进程1 获取到 B 锁
  # 进程1 释放 B 锁
  # 进程1 释放 A 锁
  # 进程2 获取到 B 锁
  # 进程2 获取到 A 锁
  # 进程2 释放 A 锁
  # 进程2 释放 B 锁
  # 进程执行完毕
  ```

## 信号量

- 同进程的一样, Semaphore管理一个内置的计数器, 每当调用acquire()时内置计数器-1；调用release() 时内置计数器+1；计数器不能小于0；当计数器为0时，acquire()将阻塞线程直到其他线程调用release()

```python
from threading import Thread
from threading import Semaphore
import threading
import time


def get_current_time():
    return time.strftime('%X')


def func():
    th = threading.current_thread()
    thread_name = th.name

    sem.acquire()
    print(f'{thread_name} 在 {get_current_time()} 执行')
    time.sleep(2)
    sem.release()


if __name__ == '__main__':
    sem = Semaphore(3)

    thread_list = []
    for item in range(10):
        th = Thread(target=func, name=f'线程{item}')
        thread_list.append(th)

    [item.start() for item in thread_list]
    [item.join() for item in thread_list]

    print(f'主线程执行完毕')

# 线程0 在 15:08:10 执行
# 线程1 在 15:08:10 执行
# 线程2 在 15:08:10 执行
# 线程3 在 15:08:12 执行
# 线程4 在 15:08:12 执行
# 线程5 在 15:08:12 执行
# 线程7 在 15:08:14 执行
# 线程6 在 15:08:14 执行
# 线程8 在 15:08:14 执行
# 线程9 在 15:08:16 执行
# 主线程执行完毕
```

## 事件

- 同进程的一样, 线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其他线程需要通过判断某个线程的状态来确定自己下一步的操作,这时线程同步问题就会变得非常棘手。
- 为了解决这些问题,我们需要使用threading库中的Event对象。 对象包含一个可由线程设置的信号标志,它允许线程等待某些事件的发生。在 初始情况下,Event对象中的信号标志被设置为假。如果有线程等待一个Event对象, 而这个Event对象的标志为假,那么这个线程将会被一直阻塞直至该标志为真。一个线程如果将一个Event对象的信号标志设置为真,它将唤醒所有等待这个Event对象的线程。如果一个线程等待一个已经被设置为真的Event对象,那么它将忽略这个事件, 继续执行

### 方法介绍

- event.isSet()：返回event的状态值
- event.wait()：如果 event.isSet()==False将阻塞线程；
- event.set()： 设置event的状态值为True，所有阻塞池的线程激活进入就绪状态， 等待操作系统调度；
- event.clear()：恢复event的状态值为False

### 示例

```python
# 模拟mysql的连接, 如果连接失败等待1s后进行重试, 失败3次提示连接失败

from threading import Thread
from threading import Event
import time
import random


def get_current_time():
    return time.strftime('%X')


def connect_mysql():
    connect_count = 1
    while 1:
        if event.is_set():
            print(f'连接成功')
            break
        elif connect_count > 3:
            print(f'连接失败')
            break
        else:
            print(f'{get_current_time()} 第 {connect_count} 次尝试连接, 连接失败')
            connect_count += 1
            # 不加参数的情况下是阻塞, 直到收到 event.set() 为止
            # 如果设置了一个参数, 这个参数代表等待的秒数
            # 这里等待1s, 1s后再回到循环中进行判断
            event.wait(1)


def change_state():
    time.sleep(random.randint(2, 5))
    event.set()


if __name__ == '__main__':
    event = Event()

    state_th = Thread(target=change_state)
    state_th.start()

    conn_th = Thread(target=connect_mysql)
    conn_th.start()

    state_th.join()
    conn_th.join()

# 情形1:
# 15:33:54 第 1 次尝试连接, 连接失败
# 15:33:55 第 2 次尝试连接, 连接失败
# 15:33:56 第 3 次尝试连接, 连接失败
# 连接失败

# 情形2:
# 15:34:28 第 1 次尝试连接, 连接失败
# 15:34:29 第 2 次尝试连接, 连接失败
# 连接成功
```

## 条件

- 使得线程等待，只有满足某条件时，才释放n个线程
- Python提供的Condition对象提供了对复杂线程同步问题的支持。Condition被称为条件变量，除了提供与Lock类似的acquire和release方法外，还提供了wait和notify方法。线程首先acquire一个条件变量，然后判断一些条件。如果条件不满足则wait；如果条件满足，进行一些处理改变条件后，通过notify方法通知其他线程，其他处于wait状态的线程接到通知后会重新判断条件。不断的重复这一过程，从而解决复杂的同步问题

```python
import threading
import time


def get_current_time():
    return time.strftime('%X')


def run():
    name = threading.current_thread().name

    con.acquire()
    con.wait()
    print(f'{name} 在 {get_current_time()} 执行')
    con.release()


if __name__ == '__main__':

    # 创建条件
    con = threading.Condition()
    for i in range(10):
        t = threading.Thread(target=run, name=f'线程{i}')
        t.start()

    while True:
        inp = input('请输入开启的线程个数 : ')
        if inp == 'q':
            break

        con.acquire()

        # 允许指定线程个数开启
        con.notify(int(inp))

        con.release()

    print('主线程结束')

# 请输入开启的线程个数 : 4
# 线程1 在 17:28:20 执行
# 线程2 在 17:28:20 执行
# 线程3 在 17:28:20 执行
# 线程0 在 17:28:20 执行
# 请输入开启的线程个数 : 2
# 线程5 在 17:28:23 执行
# 线程4 在 17:28:23 执行
# 请输入开启的线程个数 : q
```

## 定时器

- 定时器，指定n秒后执行某个操作

  ```python
  from threading import Timer
  import time
  
  
  def func():
      print(f"{time.strftime('%X')}")
  
  
  if __name__ == '__main__':
      # 只执行一次
      timer = Timer(interval=1, function=func)
      timer.start()
  
  # 17:32:58
  ```

## 线程队列

- queue队列 ：使用import queue，用法与进程Queue一样

  ```python
  import queue
  
  if __name__ == '__main__':
      q = queue.Queue()
      q.put(1)
      q.put('2')
      q.put([1, 2, 3])
  
      print(q.empty())
      print(q.full())
  
      print(q.qsize())
  
      print(q.get())
      # 1
  
      print(q.get())
      # 2
  
      print(q.get())
      # [1, 2, 3]
  ```

- 队列的几种形式

  - 先进先出

    默认创建的队列为先进先出形式

  - 先进后出

    类似Java的堆栈

    ```python
    import queue
    
    if __name__ == '__main__':
        q = queue.LifoQueue()
        q.put(1)
        q.put('2')
        q.put([1, 2, 3])
    
        print(q.get())
        print(q.get())
        print(q.get())
    
    # [1, 2, 3]
    # 2
    # 1
    ```

  - 优先级

    数字越小, 优先级越高

    ```python
    import queue
    
    if __name__ == '__main__':
        q = queue.PriorityQueue()
        # put进入一个元组, 元组的第一个元素是优先级(通常是数字,也可以是非数字之间的比较), 数字越小优先级越高
        q.put((10, 'a'))
        q.put((30, 'b'))
        q.put((20, 'c'))
    
        print(q.get())
        print(q.get())
        print(q.get())
    
    # (10, 'a')
    # (20, 'c')
    # (30, 'b')
    ```

## concurrent.futures模块

### 介绍

- concurrent.futures模块提供了高度封装的异步调用接口
- ThreadPoolExecutor：线程池，提供异步调用
- ProcessPoolExecutor: 进程池，提供异步调用

### 基本方法

- submit(fn, *args, **kwargs)

  异步提交任务

- map(func, *iterables, timeout=None, chunksize=1) 

  取代for循环submit的操作

- shutdown(wait=True)

  相当于进程池的pool.close()+pool.join()操作

  - wait=True，等待池内所有任务执行完毕回收完资源后才继续
  - wait=False，立即返回，并不会等待池内的任务执行完毕

  但不管wait参数为何值，整个程序都会等到所有任务执行完毕

  submit和map必须在shutdown之前

- result(timeout=None)

  取得结果

- add_done_callback(fn)

  回调函数

### 进程池

```python
from concurrent.futures import ProcessPoolExecutor

if __name__ == '__main__':
    help(ProcessPoolExecutor)
```

```
Help on class ProcessPoolExecutor in module concurrent.futures.process:

class ProcessPoolExecutor(concurrent.futures._base.Executor)
 |  ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=())
 |  
 |  This is an abstract base class for concrete asynchronous executors.
 |  
 |  Method resolution order:
 |      ProcessPoolExecutor
 |      concurrent.futures._base.Executor
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, max_workers=None, mp_context=None, initializer=None, initargs=())
 |      Initializes a new ProcessPoolExecutor instance.
 |      
 |      Args:
 |          max_workers: The maximum number of processes that can be used to
 |              execute the given calls. If None or not given then as many
 |              worker processes will be created as the machine has processors.
 |          mp_context: A multiprocessing context to launch the workers. This
 |              object should provide SimpleQueue, Queue and Process.
 |          initializer: An callable used to initialize worker processes.
 |          initargs: A tuple of arguments to pass to the initializer.
 |  
 |  map(self, fn, *iterables, timeout=None, chunksize=1)
 |      Returns an iterator equivalent to map(fn, iter).
 |      
 |      Args:
 |          fn: A callable that will take as many arguments as there are
 |              passed iterables.
 |          timeout: The maximum number of seconds to wait. If None, then there
 |              is no limit on the wait time.
 |          chunksize: If greater than one, the iterables will be chopped into
 |              chunks of size chunksize and submitted to the process pool.
 |              If set to one, the items in the list will be sent one at a time.
 |      
 |      Returns:
 |          An iterator equivalent to: map(func, *iterables) but the calls may
 |          be evaluated out-of-order.
 |      
 |      Raises:
 |          TimeoutError: If the entire result iterator could not be generated
 |              before the given timeout.
 |          Exception: If fn(*args) raises for any values.
 |  
 |  shutdown(self, wait=True)
 |      Clean-up the resources associated with the Executor.
 |      
 |      It is safe to call this method several times. Otherwise, no other
 |      methods can be called after this one.
 |      
 |      Args:
 |          wait: If True then shutdown will not return until all running
 |              futures have finished executing and the resources used by the
 |              executor have been reclaimed.
 |  
 |  submit(self, fn, *args, **kwargs)
 |      Submits a callable to be executed with the given arguments.
 |      
 |      Schedules the callable to be executed as fn(*args, **kwargs) and returns
 |      a Future instance representing the execution of the callable.
 |      
 |      Returns:
 |          A Future representing the given call.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from concurrent.futures._base.Executor:
 |  
 |  __enter__(self)
 |  
 |  __exit__(self, exc_type, exc_val, exc_tb)
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from concurrent.futures._base.Executor:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
```

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    print(f'子进程 {pro.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


if __name__ == '__main__':
    # 创建进程池
    executor = ProcessPoolExecutor()

    feature_list = []
    for item in range(5):
        # 通过进程池执行任务
        future = executor.submit(func, item)
        feature_list.append(future)

    executor.shutdown()

    print(f'主进程执行完毕')

    for item in feature_list:
        # 获取每个进程的结果
        print(item.result())

# 子进程 SpawnProcess-2 在 19:45:37 执行 : 0
# 子进程 SpawnProcess-6 在 19:45:37 执行 : 1
# 子进程 SpawnProcess-4 在 19:45:37 执行 : 2
# 子进程 SpawnProcess-8 在 19:45:37 执行 : 3
# 子进程 SpawnProcess-3 在 19:45:37 执行 : 4
# 主进程执行完毕
# 0
# 1
# 4
# 9
# 16
```

### 线程池

- 与进程池的操作类似

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import threading
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    time.sleep(1)
    print(f'进程 {pro.name} 子线程 {th.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


if __name__ == '__main__':
    executor = ThreadPoolExecutor()

    feature_list = []
    for item in range(5):
        feature = executor.submit(func, item)
        feature_list.append(feature)

    executor.shutdown()

    for item in feature_list:
        print(item.result())

# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 在 19:52:14 执行 : 2
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 在 19:52:14 执行 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 在 19:52:14 执行 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 在 19:52:14 执行 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 在 19:52:14 执行 : 3
# 0
# 1
# 4
# 9
# 16
```

### map操作

- 简化了 for + submit 操作
- 缺点: 不能获取返回值

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import threading
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    time.sleep(1)
    print(f'进程 {pro.name} 子线程 {th.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


if __name__ == '__main__':
    executor = ThreadPoolExecutor()

    data_iter = (item for item in range(5))
    executor.map(func, data_iter)

    executor.shutdown()

# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 在 19:56:41 执行 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 在 19:56:41 执行 : 2
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 在 19:56:41 执行 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 在 19:56:41 执行 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 在 19:56:41 执行 : 3
```

### 回调函数

```python
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ProcessPoolExecutor
import multiprocessing
import threading
import time


def get_current_time():
    """
    获取当前时间
    :return:
    """
    return time.strftime('%X')


def func(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    time.sleep(1)
    print(f'进程 {pro.name} 子线程 {th.name} 在 {get_current_time()} 执行 : {data}')
    return data ** 2


def func_callback(data):
    pro = multiprocessing.current_process()
    th = threading.current_thread()
    print(f'进程 {pro.name} 子线程 {th.name} 获取回调的值 : {data.result()}')


if __name__ == '__main__':
    executor = ThreadPoolExecutor()

    for item in range(5):
        # 设置回调函数
        executor.submit(func, item).add_done_callback(func_callback)

    executor.shutdown()

# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 在 20:02:33 执行 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_0 获取回调的值 : 0
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 在 20:02:33 执行 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 在 20:02:33 执行 : 2
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_2 获取回调的值 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_1 获取回调的值 : 1
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 在 20:02:33 执行 : 3
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_3 获取回调的值 : 9
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 在 20:02:33 执行 : 4
# 进程 MainProcess 子线程 ThreadPoolExecutor-0_4 获取回调的值 : 16
```

### 案例:爬取网页数据

```python
from concurrent.futures import ThreadPoolExecutor
import requests


def request_url(url):
    data = requests.get(url)
    return {
        'url': data.url,
        'status_code': data.status_code,
        'content_length': len(data.content)
    }


def request_callback(url_data):
    print(url_data.result())


if __name__ == '__main__':
    url_list = [
        'http://www.baidu.com',
        'http://www.qq.com',
        'http://www.163.com',
        'http://www.hao123.com',
    ]

    executor = ThreadPoolExecutor()

    for item in url_list:
        executor.submit(request_url, item).add_done_callback(request_callback)

    executor.shutdown()

# {'url': 'http://www.baidu.com/', 'status_code': 200, 'content_length': 2381}
# {'url': 'http://www.qq.com/', 'status_code': 200, 'content_length': 245170}
# {'url': 'http://www.163.com/', 'status_code': 200, 'content_length': 704972}
# {'url': 'http://www.hao123.com/', 'status_code': 200, 'content_length': 509395}
```